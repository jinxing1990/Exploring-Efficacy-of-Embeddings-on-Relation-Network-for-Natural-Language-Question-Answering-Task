{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import callbacks\n",
    "from keras.datasets import mnist\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "from keras import backend as K\n",
    "from sklearn import preprocessing\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/nvaitc/Documents/repos/ML-RN-Project'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Generate x_test and y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(995, 190, 1576)\n",
      "(995,)\n"
     ]
    }
   ],
   "source": [
    "RN_input_test = np.load('RN_input_test.npy')\n",
    "a_test = np.load('a_test.npy')\n",
    "print (RN_input_test.shape)\n",
    "print (a_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "[[0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "le_test = preprocessing.LabelEncoder()\n",
    "le_test.fit(a_test)\n",
    "test_labels = le_test.transform(a_test)\n",
    "\n",
    "l = len(np.unique(test_labels))\n",
    "print(l)\n",
    "\n",
    "one_hot_labels = keras.utils.to_categorical(test_labels, num_classes=l)\n",
    "print(one_hot_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(995, 190, 1576)\n",
      "(995, 6)\n"
     ]
    }
   ],
   "source": [
    "x_test = RN_input_test\n",
    "y_test = one_hot_labels\n",
    "\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note:\n",
    "\n",
    "- All models are run with batch size = 64, epoch = 200, validation split = 10% (unless otherwise stated).\n",
    "\n",
    "- Original model: g = [256,256,256,256] and f = [256,512,6] with 50% dropout rate at 2nd layer of f. ReLu activation for all except last layer of f, which is softmax. Before passing the output from g to f, it is summed over 190 combinations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Comparison between different sample sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(make a table to compare training and validation accuracy)\n",
    "\n",
    "...\n",
    "\n",
    "Embedded c without labels: Validation Accuracy = ~74-75%\n",
    "\n",
    "Embedded c with labels: Validation Accuracy = ~85-85%\n",
    "\n",
    "Conclusion: It is important to include labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Comparison between different RN inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(make a table to compare training and validation accuracy)\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Comparison between different modification of models [with RN inputs (original)]\n",
    "\n",
    "(a) Original model ( g = [256 x 4], f = [256,512,6] )\n",
    "\n",
    "(b) Increase number of layers in g from 4 to 6 ( g = [256 x 6], f = [256,512,6] )\n",
    "\n",
    "(c) Increase number of layers in g from 4 to 8 ( g = [256 x 8], f = [256,512,6] )\n",
    "\n",
    "(d) Increase number of neurons in each layer of g from 256 to 512 ( g = [512 x 4], f = [256,512,6] )\n",
    "\n",
    "(e) Increase number of neurons in each layer of g from 256 to 512 and 1st layer of f from 256 to 512 ( g = [512 x 4], f = [512,512,6] )\n",
    "\n",
    "(f) Increase number of neurons in each layer of g from 256 to 512. And increase number of layers in g from 4 to 6. ( g = [512 x 6], f = [256,512,6] )\n",
    "\n",
    "(g) Increase number of neurons in each layer of g from 256 to 512 and 1st layer of f from 256 to 512. And increase number of layers in g from 4 to 6. ( g = [512 x 6], f = [512,512,6] )\n",
    "\n",
    "(h) Double the number of neurons in all layers except for the last layer of f. Increase the number of layers of g from 4 to 6. ( g = [512 x 6], f = [512,1024,6] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) Original model ( g = [256,256,256,256], f = [256,512,6] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/home/nvaitc/Documents/repos/ML-RN-Project/model_ori')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load json and create model_ori\n",
    "\n",
    "model_ori_json_file = open(\"model_ori.json\",\"r\")\n",
    "loaded_model_ori_json = model_ori_json_file.read()\n",
    "model_ori_json_file.close()\n",
    "model_ori = model_from_json(loaded_model_ori_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "#load weights into new model_ori\n",
    "\n",
    "model_ori.load_weights(\"W_ori_159_0.87.h5\")\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy on model_ori: 100%\n",
      "Validation Accuracy on model_ori: 87.1%\n",
      "Test Accuracy on model_ori:  85.5 %\n"
     ]
    }
   ],
   "source": [
    "#evaluate loaded model on test data\n",
    "\n",
    "model_ori.compile(optimizer = Adam(lr = 2e-4), loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "score_ori = model_ori.evaluate(x_test,y_test,verbose = 0)\n",
    "print(\"Training Accuracy on model_ori: 100%\")\n",
    "print(\"Validation Accuracy on model_ori: 87.1%\")\n",
    "print(\"Test Accuracy on model_ori: \", \"{0:0.1f}\".format(score_ori[1]*100), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/home/nvaitc/Documents/repos/ML-RN-Project')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Increase number of layers in g from 4 to 6 ( g = [256,256,256,256,256,256], f = [256,512,6] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/home/nvaitc/Documents/repos/ML-RN-Project/model_g6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load json and create model_ori\n",
    "\n",
    "model_g6_json_file = open(\"model_g6.json\",\"r\")\n",
    "loaded_model_g6_json = model_g6_json_file.read()\n",
    "model_g6_json_file.close()\n",
    "model_g6 = model_from_json(loaded_model_g6_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "#load weights into new model_ori\n",
    "\n",
    "model_g6.load_weights(\"W_g6_188_0.89.h5\")\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy on model_g6: 100%\n",
      "Validation Accuracy on model_g6: 89.1%\n",
      "Test Accuracy on model_g6:  88.4 %\n"
     ]
    }
   ],
   "source": [
    "#evaluate loaded model on test data\n",
    "\n",
    "model_g6.compile(optimizer = Adam(lr = 2e-4), loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "score_g6 = model_g6.evaluate(x_test,y_test,verbose = 0)\n",
    "print(\"Training Accuracy on model_g6: 100%\")\n",
    "print(\"Validation Accuracy on model_g6: 89.1%\")\n",
    "print(\"Test Accuracy on model_g6: \", \"{0:0.1f}\".format(score_g6[1]*100), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/home/nvaitc/Documents/repos/ML-RN-Project')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c) Increase number of layers in g from 4 to 8 ( g = [256 x 8], f = [256,512,6] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/home/nvaitc/Documents/repos/ML-RN-Project/model_g8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load json and create model_ori\n",
    "\n",
    "model_g8_json_file = open(\"model_g8.json\",\"r\")\n",
    "loaded_model_g8_json = model_g8_json_file.read()\n",
    "model_g8_json_file.close()\n",
    "model_g8 = model_from_json(loaded_model_g8_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "#load weights into new model_ori\n",
    "\n",
    "model_g8.load_weights(\"W_g8_05_0.22.h5\")\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy on model_g8: 18.4%\n",
      "Validation Accuracy on model_g8: 22.2%\n",
      "Test Accuracy on model_g8:  20.0 %\n"
     ]
    }
   ],
   "source": [
    "#evaluate loaded model on test data\n",
    "\n",
    "model_g8.compile(optimizer = Adam(lr = 2e-4), loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "score_g8 = model_g8.evaluate(x_test,y_test,verbose = 0)\n",
    "print(\"Training Accuracy on model_g8: 18.4%\")\n",
    "print(\"Validation Accuracy on model_g8: 22.2%\")\n",
    "print(\"Test Accuracy on model_g8: \", \"{0:0.1f}\".format(score_g8[1]*100), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/home/nvaitc/Documents/repos/ML-RN-Project')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (d) Increase number of neurons in each layer of g from 256 to 512 ( g = [512 x 4], f = [256,512,6] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/home/nvaitc/Documents/repos/ML-RN-Project/model_512')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load json and create model_ori\n",
    "\n",
    "model_512_json_file = open(\"model_512.json\",\"r\")\n",
    "loaded_model_512_json = model_512_json_file.read()\n",
    "model_512_json_file.close()\n",
    "model_512 = model_from_json(loaded_model_512_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "#load weights into new model_ori\n",
    "\n",
    "model_512.load_weights(\"W_512_179_0.88.h5\")\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy on model_512: 100%\n",
      "Validation Accuracy on model_512: 88.2%\n",
      "Test Accuracy on model_512:  85.0 %\n"
     ]
    }
   ],
   "source": [
    "#evaluate loaded model on test data\n",
    "\n",
    "model_512.compile(optimizer = Adam(lr = 2e-4), loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "score_512 = model_512.evaluate(x_test,y_test,verbose = 0)\n",
    "print(\"Training Accuracy on model_512: 100%\")\n",
    "print(\"Validation Accuracy on model_512: 88.2%\")\n",
    "print(\"Test Accuracy on model_512: \", \"{0:0.1f}\".format(score_512[1]*100), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/home/nvaitc/Documents/repos/ML-RN-Project')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (e) Increase number of neurons in each layer of g from 256 to 512 and 1st layer of from 256 to 512 ( g = [512 x 4], f = [512,512,6] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/home/nvaitc/Documents/repos/ML-RN-Project/model_512f512')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load json and create model_ori\n",
    "\n",
    "model_512f512_json_file = open(\"model_512f512.json\",\"r\")\n",
    "loaded_model_512f512_json = model_512f512_json_file.read()\n",
    "model_512f512_json_file.close()\n",
    "model_512f512 = model_from_json(loaded_model_512f512_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "#load weights into new model_ori\n",
    "\n",
    "model_512f512.load_weights(\"W_512f512_193_0.88.h5\")\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy on model_512f512: 99.9%\n",
      "Validation Accuracy on model_512f512: 87.9%\n",
      "Test Accuracy on model_512f512:  88.3 %\n"
     ]
    }
   ],
   "source": [
    "#evaluate loaded model on test data\n",
    "\n",
    "model_512f512.compile(optimizer = Adam(lr = 2e-4), loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "score_512f512 = model_512f512.evaluate(x_test,y_test,verbose = 0)\n",
    "print(\"Training Accuracy on model_512f512: 99.9%\")\n",
    "print(\"Validation Accuracy on model_512f512: 87.9%\")\n",
    "print(\"Test Accuracy on model_512f512: \", \"{0:0.1f}\".format(score_512f512[1]*100), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/home/nvaitc/Documents/repos/ML-RN-Project')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (f) Increase number of neurons in each layer of g from 256 to 512. And increase number of layers in g from 4 to 6. ( g = [512 x 6], f = [256,512,6] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/home/nvaitc/Documents/repos/ML-RN-Project/model_g6x512')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load json and create model_ori\n",
    "\n",
    "model_g6x512_json_file = open(\"model_g6x512.json\",\"r\")\n",
    "loaded_model_g6x512_json = model_g6x512_json_file.read()\n",
    "model_g6x512_json_file.close()\n",
    "model_g6x512 = model_from_json(loaded_model_g6x512_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "#load weights into new model_ori\n",
    "\n",
    "model_g6x512.load_weights(\"W_g6x512_164_0.88.h5\")\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy on model_g6x512: 100%\n",
      "Validation Accuracy on model_g6x512: 87.8%\n",
      "Test Accuracy on model_g6x512:  88.5 %\n"
     ]
    }
   ],
   "source": [
    "#evaluate loaded model on test data\n",
    "\n",
    "model_g6x512.compile(optimizer = Adam(lr = 2e-4), loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "score_g6x512 = model_g6x512.evaluate(x_test,y_test,verbose = 0)\n",
    "print(\"Training Accuracy on model_g6x512: 100%\")\n",
    "print(\"Validation Accuracy on model_g6x512: 87.8%\")\n",
    "print(\"Test Accuracy on model_g6x512: \", \"{0:0.1f}\".format(score_g6x512[1]*100), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/home/nvaitc/Documents/repos/ML-RN-Project')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (g) Increase number of neurons in each layer of g from 256 to 512 and 1st layer of f from 256 to 512. And increase number of layers in g from 4 to 6. ( g = [512 x 6], f = [512,512,6] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/home/nvaitc/Documents/repos/ML-RN-Project/model_g6x512f512')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load json and create model_ori\n",
    "\n",
    "model_g6x512f512_json_file = open(\"model_g6x512f512.json\",\"r\")\n",
    "loaded_model_g6x512f512_json = model_g6x512f512_json_file.read()\n",
    "model_g6x512f512_json_file.close()\n",
    "model_g6x512f512 = model_from_json(loaded_model_g6x512f512_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "#load weights into new model_ori\n",
    "\n",
    "model_g6x512f512.load_weights(\"W_g6x512f512_179_0.88.h5\")\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy on model_g6x512f512: 99.7%\n",
      "Validation Accuracy on model_g6x512f512: 88.3%\n",
      "Test Accuracy on model_g6x512f512:  89.0 %\n"
     ]
    }
   ],
   "source": [
    "#evaluate loaded model on test data\n",
    "\n",
    "model_g6x512f512.compile(optimizer = Adam(lr = 2e-4), loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "score_g6x512f512 = model_g6x512f512.evaluate(x_test,y_test,verbose = 0)\n",
    "print(\"Training Accuracy on model_g6x512f512: 99.7%\")\n",
    "print(\"Validation Accuracy on model_g6x512f512: 88.3%\")\n",
    "print(\"Test Accuracy on model_g6x512f512: \", \"{0:0.1f}\".format(score_g6x512f512[1]*100), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/home/nvaitc/Documents/repos/ML-RN-Project')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (h) Double the number of neurons in all layers except for the last layer of f. Increase the number of layers of g from 4 to 6. ( g = [512 x 6], f = [512,1024,6] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/home/nvaitc/Documents/repos/ML-RN-Project/model_double')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load json and create model_ori\n",
    "\n",
    "model_double_json_file = open(\"model_double.json\",\"r\")\n",
    "loaded_model_double_json = model_double_json_file.read()\n",
    "model_double_json_file.close()\n",
    "model_double = model_from_json(loaded_model_double_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "#load weights into new model_ori\n",
    "\n",
    "model_double.load_weights(\"W_double_177_0.88.h5\")\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy on model_double: 100%\n",
      "Validation Accuracy on model_double: 88.2%\n",
      "Test Accuracy on model_double:  88.4 %\n"
     ]
    }
   ],
   "source": [
    "#evaluate loaded model on test data\n",
    "\n",
    "model_double.compile(optimizer = Adam(lr = 2e-4), loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "score_double = model_double.evaluate(x_test,y_test,verbose = 0)\n",
    "print(\"Training Accuracy on model_double: 100%\")\n",
    "print(\"Validation Accuracy on model_double: 88.2%\")\n",
    "print(\"Test Accuracy on model_double: \", \"{0:0.1f}\".format(score_double[1]*100), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments and Results\n",
    "\n",
    "\n",
    "\n",
    "We have made several comparison between different types of embeddings, different sample sizes, different types of inputs to feed to the RN module and different modifications to the RN module with our implementation of USE embeddings. We compared the accuracy of the test set for different modifications to the RN module and compared the accuracy of the validation set for the rest of the comparisons.\n",
    "\n",
    "For the experiments, all models were run with batch size of 64, with 200 epochs and validation set was taken from the last 10\\% of the training set. For the original RN module, $f_\\phi \\left(\\sum_{i,j} g_\\theta (o_i,o_j,q)\\right)$, $g_\\theta$ is a four-layer MLP 256 unites per layer and $f_\\phi$ is a three-layer MLP consisting of 256, 512 and 6 units, where the final softmax output was optimized with a cross-entropy loss function using the Adam optimizer with a learning rate of $2e^{-4}$. All models are run on original RN module except for the different modifications to the RN module.\n",
    "\n",
    "\n",
    "\n",
    "## Comparison between Different Embeddings\n",
    "\n",
    "\n",
    "\n",
    "We have made comparisons between the two different embeddings of the sentences of the contexts, questions and answers and below are the result:\n",
    "\n",
    "$\n",
    "\n",
    "\\begin{tabular}{|c|c|c|}\n",
    "\n",
    "\\hline\n",
    "&&\\\\\n",
    "\\hline\n",
    "&&\\\\\n",
    "\\hline\n",
    "\n",
    "\\end{tabular}\n",
    "\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
