Deep learning has made it possible to do classification of objects in images and translation of
languages, often with incredible accuracy. This is achieved due to the ability of neural networks to pick out important patterns that are inconceivable to the human eye, from large quantities of labeled data. However, just being able to learn patterns is not sufficient as it is not the only ability associated to intelligence; reasoning is another essential ability that separates humans from machines. Hence,in recent years there is much work on reasoning related research, like visual reasoning where the machine is able to give an answer given an image and a visual question about the image, and text-based question answering where the machine is able to answer a question based on the earlier sentences given to it.

In this project, we focus on the text-based question answering task using relation network (RN) on the bAbI dataset. RNs are networks that are designed based on relational reasoning, where its capacity to compute relations is baked into the architecture without having the neural network to learn it.

For any neural approach for natural language processing, word and sentence embeddings are indispensible. They allow us to represent words and sentences whose original forms are strings, as vectors which then we can feed it into an artificial neural network. There are various ways to embed words, and while unsupervised representations have been the more commonly used approach, using the assumption that you can tell a word by the company it keeps, there is an increased focus on supervised representations and also multi-task learning of representations. In our project, we explore how different types of embeddings, in particular, how the traditional unsupervised representations compare up to representations obtained from multi-task learning.

Our experiments involve using two different representations, the first one being the approach used by the original RN paper, to embed the context and questions into sentence embeddings using LSTMs, and the other uses the universal sentence encoder (USE) to embed the context and questions into sentence embeddings. In the RN paper, sentence embeddings are called objects which the RN is used to learn the relation between them. We then compare the performance of different embeddings on RN for bAbI question answering task.